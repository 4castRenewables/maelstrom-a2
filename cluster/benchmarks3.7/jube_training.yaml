name:    ap2-all
outpath: ap2_run
comment: MAELSTROM AP2 benchmark jube script for training

parameterset:
  - name: appParameter
    parameter:
      - name: iteration
        tag: benchs
        type: int
        _: 1,2,3
      - name: iteration
        tag: "!benchs"
        type: int
        _: 1

      - name: path_apptainer_image
        tag: "jnvidia"
        type: string
        _: /p/project/deepacf/maelstrom/ehlert1/apptainer_images/ap2deberta.sif
      - name: path_apptainer_image
        tag: "e4"
        type: string
        _: /home/kehlert/code/a2/apptainer_images/a2-rocm.sif
      - name: path_apptainer_image
        tag: "h100"
        type: string
        _: /p/project/deepacf/maelstrom/ehlert1/a2/cluster/benchmarks3.7/pytorch_23.10-py3.sif
      - name: path_apptainer_image
        tag: "mi250"
        type: string
        _: /p/project/deepacf/maelstrom/ehlert1/apptainer_images/a2-rocm.sif
      - name: mount_path_dataset
        type: str
        _: /data
      - name: base_path_training_set
        tag: "!e4+!datamedium+!datalarge"
        type: str
        _: /p/project/deepacf/maelstrom/ehlert1/a2/cluster/benchmarks3.7/ap2_run/000005/000000_submit/work/output_model/dataset_split_thresh0M2/
      - name: base_path_training_set
        tag: "!e4+datamedium"
        type: str
        _: /p/project/deepacf/maelstrom/ehlert1/a2/cluster/benchmarks3.7/ap2_run/000011/000000_submit/work/output_model//dataset_split_thresh0M2/
      - name: base_path_training_set
        tag: "!e4+datalarge"
        type: str
        _: /p/project/deepacf/maelstrom/ehlert1/a2/cluster/benchmarks3.7/ap2_run/000033/000000_submit/work/output_model//dataset_split_thresh0M2/
      - name: filename_dataset_train
        tag: "!datamedium+!datalarge"
        type: str
        _: ${base_path_training_set}/tweets_2017_01_era5_normed_filtered_train.nc
      - name: filename_dataset_validate
        tag: "!datamedium+!datalarge"
        type: str
        _: ${base_path_training_set}/tweets_2017_01_era5_normed_filtered_validate.nc
      - name: filename_dataset_test
        tag: "!datamedium+!datalarge"
        type: str
        _: ${base_path_training_set}/tweets_2017_01_era5_normed_filtered_test.nc
      - name: filename_dataset_train
        tag: datamedium
        type: str
        _: ${base_path_training_set}/tweets_2017_era5_normed_filtered_train.nc
      - name: filename_dataset_validate
        tag: datamedium
        type: str
        _: ${base_path_training_set}/tweets_2017_era5_normed_filtered_validate.nc
      - name: filename_dataset_test
        tag: datamedium
        type: str
        _: ${base_path_training_set}/tweets_2017_era5_normed_filtered_test.nc
      - name: filename_dataset_train
        tag: datalarge
        type: str
        _: ${base_path_training_set}/tweets_2017-2020_era5_normed_filtered_train.nc
      - name: filename_dataset_validate
        tag: datalarge
        type: str
        _: ${base_path_training_set}/tweets_2017-2020_era5_normed_filtered_validate.nc
      - name: filename_dataset_test
        tag: datalarge
        type: str
        _: ${base_path_training_set}/tweets_2017-2020_era5_normed_filtered_test.nc
      - name: key_input
        type: string
        _: "text"
      - name: key_output
        type: string
        _: "raining"
      - name: key_raining
        type: string
        _: "raining"
      - name: key_text
        type: string
        _: "text_normalized"
      - name: base_path_dataset
        tag: "!e4"
        _: /p/project/deepacf/maelstrom/ehlert1/data/tweets/
      - name: base_path_dataset
        tag: "e4"
        _: /home/kehlert/data/tweets/
      - name: filename_tweets
        tag: split+!e4+!datamedium
        _: ${base_path_dataset}/tweets_2017_01_era5_normed_filtered.nc
      - name: filename_tweets
        tag: split+!e4+datamedium
        _: ${base_path_dataset}/tweets_2017_era5_normed_filtered.nc
      - name: filename_tweets
        tag: split+e4+datamedium
        _: ${base_path_dataset}/tweets_2017_era5_normed_filtered.nc
      - name: filename_tweets
        tag: split+!e4+datalarge
        _: ${base_path_dataset}/tweets_2017-2020_era5_normed_filtered.nc

      - name: model_path
        tag: "jwb|jwc|h100|mi250"
        _: /p/project/deepacf/maelstrom/ehlert1/deberta-v3-small/
      - name: model_path
        tag: e4
        _: /data/maelstrom/kehlert/models/deberta-v3-small
      - name: model_name
        _: deberta_small
      - name: epochs
        type: int
        _: 1
      - name: batch_size
        type: int
        _: 32
      - name: learning_rate
        type: float
        _: 0.00003
      - name: weight_decay
        type: float
        _: 0
      - name: eval_steps
        tag: test
        type: int
        _: 100
      - name: eval_steps
        tag: "!test"
        type: int
        _: 500
      - name: outdir
        type: string
        _: "$jube_wp_abspath/output_model"
      - name: run_name
        _: "${jube_benchmark_name}_${jube_benchmark_id}"

      - name: slurm_output
        type: string
        _: "$jube_wp_abspath/slurm-out.%j"
      - name: slurm_error
        type: string
        _: "$jube_wp_abspath/slurm-err.%j"
      - name: run_folder
        type: string
        _: $run_name
  - name: globalParameter
    parameter:
      - name: modules
        tag: e4
        separator: |
        _: |
          module load slurm
          echo $(module av)
      - name: modules
        tag: "!e4"
        separator: |
        _:
          module --force purge 
      - name: modules
        tag: "h100"
        separator: |
        _: |
          module --force purge
          export PYTHONPATH=/p/project/deepacf/maelstrom/ehlert1/a2/cluster/benchmarks3.7/h100_packages/local/lib/python3.10/dist-packages:$PYTHONPATH
          export PYTHONPATH=/usr/local/lib/python3.10/dist-packages/:$PYTHONPATH
          echo $PYTHONPATH
      - name: modules
        tag: "mi250"
        separator: |
        _: |
          module --force purge
          export PYTHONPATH=/p/project/deepacf/maelstrom/ehlert1/a2/cluster/benchmarks3.7/h100_packages/local/lib/python3.10/dist-packages:$PYTHONPATH
          export PYTHONPATH=/usr/local/lib/python3.10/dist-packages/:$PYTHONPATH
          echo $PYTHONPATH
      - name: modules
        tag: "!e4+!h100"
        separator: |
        _:
          module --force purge 
      - name: systemname
        tag: jwc
        _: jwc
      - name: systemname
        tag: h100
        _: jureca
      - name: systemname
        tag: jwb
        _: jwb
  - name: executeset
    init_with: platform.xml
  - name: systemParameter
    init_with: platform.xml
    parameter:
      - name: additional_setup
        mode: text
        tag: "!e4"
        separator: |
        _: |
          echo "no additional_setup"
      - name: additional_setup
        mode: text
        tag: e4
        separator: |
        _: |
          export jube_benchmark_home=${jube_benchmark_home}
          export base_path_dataset=${base_path_dataset}
          echo ${jube_benchmark_home}
          . ${jube_benchmark_home}/../../scripts/finetune_deberta/mlflow_projects/deberta_rain_classifier/run_docker_e4.sh
      - name: preprocess
        mode: text
        separator: |
        _: |
          ${power_measure_setup}
          source ~/.bashrc
          ${modules}
          export ${visible_devices}
          ${additional_setup}
      - name: power_measure_setup
        tag: e4power
        mode: text
        separator: |
        _: |
          label=$$(/opt/share/scripts/powerdiscovery/getlabel.sh)
          echo "POWERMEASUREMENT: Label = $$label"
          /opt/share/scripts/powerdiscovery/getpower_bg.sh 1000 &
      - name: power_measure_setup
        tag: "jwb|jwc|h100|!e4power"
        _: ""
      - name: postprocess
        tag: "jwb|jwc|h100|!e4power"
        _: ""
      - name: postprocess
        tag: e4power
        mode: text
        separator: |
        _: |
          kill -9 $$(cat ~/powerout.$$label.pid)
          awk '{print "POWERMEASUREMENT: " $0}' ~/powerout.$$label.csv
      - name: job_name
        _: $jube_benchmark_name-$jube_benchmark_padid-$jube_wp_padid-$jube_step_name
      - name: threadspertask
        _: 1
      - name: nodes
        _: 1
      - name: gpus
        tag: e4
        _: 1
      - name: gpus
        tag: "jwc|jwb|h100"
        _: 4
      - name: timelimit
        tag: test
        _: "01:00:00"
      - name: timelimit
        tag: "!test"
        _: "24:00:00"
      - name: account
        tag: jwb|jwc
        _: deepacf
      - name: account
        tag: h100|mi250
        _: exalab
      - name: account
        tag: e4
        _: maelstrom
      - name: gres
        _: gpu:$gpus
      - name: gres
        tag: "mi250"
        _: "None"
      - name: gres
        tag: "gracehopper"
        _: "gpu"

      - name: queue
        tag: jwb+!test
        _: booster
      - name: queue
        tag: jwb+test
        _: develbooster
      - name: queue
        tag: "e4+!e4amd"
        _: i-gpu-a100
      - name: queue
        tag: e4amd
        _: a-gpu-mi100
      - name: queue
        tag: gracehopper
        _: t-gpu-gh200
      - name: queue
        tag: gpua2
        _: i-gpu-a2
      - name: queue
        tag: jwc+!test
        _: gpus
      - name: queue
        tag: jwc+test
        _: develgpus
      - name: queue
        tag: h100
        _: dc-h100
      - name: queue
        tag: h100+test
        _: dc-h100
      - name: queue
        tag: "mi250"
        _: "dc-mi200"
      - name: apptainerbind
        _: "--nv"
      - name: apptainerbind
        tag: "mi250|gracehopper"
        _: "--rocm"
      - name: apptainer_exec
        tag: "!e4"
        _: "apptainer"
      - name: execution_command
        _: ${apptainer_exec} run ${apptainerbind} ${path_apptainer_image}
      - name: execution_command
        tag: e4+split 
        _: docker exec ap2_maelstrom python3.10 /scripts/build_dataset_rain_classifier.py ${args_exec_command}
      - name: executable
        _: ${execution_command} python3 ${jube_benchmark_home}/../../scripts/finetune_deberta/mlflow_projects/deberta_rain_classifier/finetune_deberta_classifier.py ${args_exec_command}
      - name: executable
        tag: h100
        _: >
          ${execution_command} python3 ${jube_benchmark_home}/../../scripts/finetune_deberta/mlflow_projects/deberta_rain_classifier/finetune_deberta_classifier.py ${args_exec_command}
      - name: executable
        tag: split
        _: ${execution_command} python3 ${jube_benchmark_home}/../../scripts/finetune_deberta/mlflow_projects/deberta_rain_classifier/build_dataset_rain_classifier.py ${args_exec_command}
      - name: submit_cmd
        _: sbatch
      - name: visible_devices
        type: string
        separator: ";"
        tag: jwc|jwb|h100|gpuquadro
        _: "CUDA_VISIBLE_DEVICES=0,1,2,3"
      - name: visible_devices
        type: string
        separator: ";"
        tag: mi250+!gpuquadro
        _: "CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7"
      - name: visible_devices
        type: string
        separator: ";"
        tag: gpusingle
        _: "CUDA_VISIBLE_DEVICES=0"
      - name: visible_devices
        type: string
        separator: ";"
        tag: gpudouble
        _: "CUDA_VISIBLE_DEVICES=0,1"
      - name: visible_devices
        tag: e4
        _: ""
      - name: args_exec_additional
        _: >
          ""
      - name: args_exec_additional
        tag: "!e4"
        _: >
          --log_gpu_power
      - name: args_exec_command
        mode: text
        _: >
          --filename_dataset_train ${filename_dataset_train}
          --filename_dataset_validate ${filename_dataset_validate}
          --filename_dataset_test ${filename_dataset_test}
          --key_input ${key_input}
          --key_output ${key_output}
          --key_raining ${key_raining}
          --key_text ${key_text}
          --model_path ${model_path}
          --model_name ${model_name}
          --num_labels 2
          --trainer_name deep500
          --random_seed 42
          --epochs ${epochs}
          --batch_size ${batch_size}
          --learning_rate ${learning_rate}
          --weight_decay ${weight_decay}
          --warmup_ratio 0
          --warmup_steps 0
          --hidden_dropout_prob 0.1
          --cls_dropout 0.1
          --lr_scheduler_type linear
          --loss default_loss
          --save_steps 500
          --logging_steps 1
          --evaluation_strategy epoch
          --eval_steps 500
          --output_dir ${outdir}
          --folder_run dataset_split_thresh0M2/
          --log_gpu_memory
          --job_id $${SLURM_JOBID}
          --ignore_tracking
          ${args_exec_additional}
      - name: args_exec_command
        tag: split
        mode: text
        _: >
          --filename_tweets ${filename_tweets}
          --key_precipitation tp_h_mm
          --precipitation_threshold_rain 0.01
          --key_precipitation_station tp_mm_station
          --precipitation_threshold_rain_station 0.1
          --key_distance_weather_station station_distance_km
          --maximum_distance_to_station 1
          --validation_size 0.2
          --test_size 0.2
          --output_dir ${outdir}/
          --folder_run dataset_split_thresh0M2/
          --ignore_tracking

patternset:
   - name: perf_patterns
     pattern:
      - {name: jobid, type: int, _: "Running finetuning as args.job_id=$jube_pat_int" }
      - {name: node_names, type: string, _: "Running on nodes ${jube_pat_wrd}."}
      - {name: ntweets, type: int, _: "loaded $jube_pat_int tweets"}
      - {name: epoch, type: int, _: "Epoch\\s+$jube_pat_int"}
      - {name: run_time, type: float, _: "RUN\\s+: took ${jube_pat_fp}"}
      - {name: training_time, type: float, _: "TRAINING\\s+: took ${jube_pat_fp}"}
      - {name: epoch_time, type: float, _: "EPOCH\\s+: took ${jube_pat_fp}"}
      - {name: io_time, type: float, _: "IO\\s+: took ${jube_pat_fp}"}
      - {name: forward_time, type: float, _: "FORWARD\\s+: took ${jube_pat_fp}"}
      - {name: backward_time, type: float, _: "BACKWARD\\s+: took ${jube_pat_fp}"}
      - {name: batch_time, type: float, _: "BATCH\\s+: took ${jube_pat_fp}"}
      - {name: evaluation_time, type: float, _: "EVALUATION: took ${jube_pat_fp}"}
      - {name: saving_model_time, type: float, _: "SAVING_MODEL[\\s+]?: took ${jube_pat_fp}"}
      - {name: loss, type: float, _: "{'loss': $jube_pat_fp"}
      - {name: eval_loss, type: float, _: "{'eval_loss': $jube_pat_fp"}
      - {name: max_memory, type: float, _: "Max memory consumption \\[Gbyte\\]: $jube_pat_fp"}
      - {name: nsteps, type: int, _: ", 'step': $jube_pat_int"}
      - {name: ndevices, type: string, _: "CUDA_VISIBLE_DEVICES=${jube_pat_wrd}$"}
      - {name: gpu_max_mem_allocated, type: float, _: "Gpu max memory allocated: ${jube_pat_fp}"}
      - {name: gpu_max_mem_reserved, type: float, _: "Gpu max memory reserved: ${jube_pat_fp}"}
      - {name: label_pat, type: string, _: "POWERMEASUREMENT: Label = $jube_pat_wrd"}
      - {name: time_pat, type: int, _: "POWERMEASUREMENT: $jube_pat_int,$jube_pat_nint,$jube_pat_nint"}
      - {name: watt_pat, type: int, _: "POWERMEASUREMENT: $jube_pat_nint,$jube_pat_int,$jube_pat_nint"}
      - {name: va_pat, type: int, _: "POWERMEASUREMENT: $jube_pat_nint,$jube_pat_nint,$jube_pat_int"}
      - {name: total_power_wh_per_device, type: string, _: "total_power_consumption_Wh_per_device: $jube_pat_wrd"}
      - {name: total_power_wh, type: float, _: "total_power_consumption_Wh: $jube_pat_fp"}
      - {name: total_power_w, type: string, _: "average_consumption_W_per_device: $jube_pat_wrd"}
analyser:
    name: analyse
    reduce: false
    use: perf_patterns
    analyse:
      step: submit
      file:
        - slurm-*.out
        - slurm-out.*
        - slurm-err.*
        - slurm.out
        - slurm.err
        - job.err
        - job.out
        - stdout

result:
    use: analyse
    table:
      name: result
      style: pretty
      sort: iter_pat
      column:
        - {title: "JobID", _: jobid}
        - {title: "#tweets", _: ntweets}
        #- {title: "#steps", _: nsteps_last}
        - {title: "devices", _: ndevices}
        - {title: "queue", _: queue}
        #- {title: "#nodes", _: nodes}
        - {title: "gres", _: gres}
        #- {title: "BS", _: batch_size}
        - {title: "T. run", format: ".4f", _: run_time_last}
        - {title: "T. train", format: ".4f", _: training_time_last}
        - {title: "epoch", format: ".4f", _: epoch_time_avg}
        - {title: "T. IO", format: ".4f", _: io_time_sum}
        #- {title: "Min epoch", format: ".4f", _: epoch_time_min}
        #- {title: "Max epoch", format: ".4f", _: epoch_time_max}
        - {title: "Avg. it.", format: ".4f", _: batch_time_avg}
        - {title: "Max it.", format: ".4f", _: batch_time_max}
        - {title: "loss", format: ".4f", _: loss_last}
        - {title: "evloss", format: ".4f", _: eval_loss_last}
        #- {title: "M. eval loss", format: ".4f", _: eval_loss_min}
        #- {title: "Saving time", format: ".4f", _: saving_model_time_last}
        #- {title: "l. rate", _: lr}
        #- {title: "min loss", format: ".4f", _: loss_min}
        #- {title: "# epochs", _: epochs}
        - {title: "MaMemCPU", format: ".4f",  _: max_memory}
        - {title: "MaMemGPU", format: ".4f", _: gpu_max_mem_allocated_max}
        - {title: "nodes", _: node_names}
        - {title: "T. eval", format: ".4f", _: evaluation_time_max}
        # - {title: "MaxMemReservGPU", format: ".4f", _: gpu_max_mem_reserved_max}
        #- {title: "Job_Time", _: timelimit}
        #- {title: "Node(s)", _: label_pat}
        #- {title: "Tstart", _: time_pat_first}
        #- {title: "Tend", _: time_pat_last}
        # - {title: "Ma.W", format: ".2f", _: watt_pat_max}
        # - {title: "A.W", format: ".2f", _: watt_pat_avg}
        #- {title: "Mi.W", format: ".4f", _: watt_pat_min}
        # - {title: "Ma.VA", format: ".2f", _: va_pat_max}
        # - {title: "A.VA", format: ".2f", _: va_pat_avg}
        #- {title: "Mi.VA", format: ".4f", _: va_pat_min}
        # - {title: "PpDevWh", _: total_power_wh_per_device}
        # - {title: "PWh", format: ".2f", _: total_power_wh}
        # - {title: "PW", _: total_power_w}

step:
  - name: submit
    use:
      - appParameter
      - globalParameter
      - systemParameter
      - executeset
      - from: platform.xml
        _: jobfiles
      - from: platform.xml
        _: executesub
    do:
      done_file: $ready_file
      error_file: $error_file
      _:
        $modules;
        $submit $submit_script;
