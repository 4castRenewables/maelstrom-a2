{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f33acd9-e3cd-469a-a8b3-22e0b02347c8",
   "metadata": {},
   "source": [
    "# Training deBERTa (base version) classifier for sentimental analysis of Reddit data\n",
    "Training a deep learning model (deBERTa) that is based on the transformer architecture as part of the BERT encoder, which lies at the heart of the model. The model and pre-trained weights taken from [hugging face](https://huggingface.co/microsoft/deberta-v3-base). deBerta is generally proposed in [this paper](https://arxiv.org/abs/2006.03654). Here, we take their second smallest model as listed [here](https://huggingface.co/microsoft/deberta-v3-small).\n",
    "\n",
    "Results:\n",
    "- f1 score   macro avg: 0.74\n",
    "- f1 score  weighted avg: 0.79\n",
    "\n",
    "Note (from [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)):\n",
    "- F1 = 2 * (precision * recall) / (precision + recall)\n",
    "- 'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "- 'macro': Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "\n",
    "Also varied hyperparameters with the following results:\n",
    "- learning rate/10 (0.73, 0.78)\n",
    "\n",
    "And only trained weights of the classifier, which failed, possibly too few weights available?!\n",
    "- *finetuning* (couldn't learn)\n",
    "\n",
    "Model weights:\\\n",
    "Weights need to be downloaded from the [repo of microsoft/deberta-v3-base](https://huggingface.co/microsoft/deberta-v3-base/tree/main) and put in the folder of execution to use them.\n",
    "\n",
    "Data:\\\n",
    "Data is downloaded when the notebook is executed from hugging face.\n",
    "\n",
    "Generally, model seems rather memory bound and larger batchsizes result in memory errors. Maybe parallelization not optimized for memory in current configuration..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea967c4d-7e76-4169-a512-54f17773de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://www.kaggle.com/code/tanlikesmath/feedback-prize-effectiveness-eda-deberta-baseline/notebook\n",
    "# transformers taken from https://huggingface.co/microsoft/deberta-v3-small\n",
    "\n",
    "# changed to larger model here: https://huggingface.co/microsoft/deberta-v3-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda676a8-75ec-4d7d-9ff2-6346725169f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows update of external libraries without need to reload package\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16846587-c414-4b19-898b-f319fad78afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import utils\n",
    "\n",
    "import torch\n",
    "\n",
    "import datasets\n",
    "\n",
    "import skmultilearn.model_selection.iterative_stratification\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0972a8df-c84d-486c-8f4c-be9dde9bc35d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set all gpus to available gpus (not required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ec53b-e6cd-4311-9086-f2f9ceab60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2582efc-4414-431a-a8cb-37e7a5c48971",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c481aa-5cd5-4e28-84f2-45abd147cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # empties gpu memory, may be required when interrupting training due bugs/user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a976e-41cd-4c19-91b2-8c037de9abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = (\n",
    "    \"/p/project/deepacf/maelstrom/ehlert1/deberta-v3-base\"  # model repo downloaded from hugging face see link above\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c4ec5c-bda5-4945-ba30-426068504c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /p/project/deepacf/maelstrom/ehlert1/deberta-v3-small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93c2c50-9624-4b6e-b262-cf5e9bf8ed74",
   "metadata": {},
   "source": [
    "## Tokenize data with same tokenizer used for pre-training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f394a-d71d-4dd4-a6ee-7f0a27de5991",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ddb325-7fd0-4cce-9602-ed33f572315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "separator_token = tokenizer.sep_token\n",
    "tokenizer.SPECIAL_TOKENS_ATTRIBUTES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e3fd9-ea55-4c19-9d3a-d0d4dac16380",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a77cd1-8763-419a-b1f5-61710c0d2af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 28\n",
    "emotions = datasets.load_dataset(\"go_emotions\", \"simplified\")\n",
    "df_raw = pd.concat(\n",
    "    [\n",
    "        emotions.data[\"train\"].table.to_pandas(),\n",
    "        emotions.data[\"validation\"].table.to_pandas(),\n",
    "        emotions.data[\"test\"].table.to_pandas(),\n",
    "    ]\n",
    ")\n",
    "y_raw = utils.convert_df_labels(df_raw, num_labels)\n",
    "df_unique = utils.remove_ambiguous_data(df_raw, y_raw)\n",
    "# updated data frame shape, therefore need to recompute y labels\n",
    "y_unique = utils.convert_df_labels(df_unique, num_labels)\n",
    "# explanation for iterative stratification of labels http://videolectures.net/ecmlpkdd2011_tsoumakas_stratification/?q=stratification%20multi%20label\n",
    "(\n",
    "    indices_train,\n",
    "    y_train,\n",
    "    indices_test,\n",
    "    y_test,\n",
    ") = skmultilearn.model_selection.iterative_stratification.iterative_train_test_split(\n",
    "    np.arange(df_unique.shape[0]).reshape(-1, 1), y_unique, 0.1\n",
    ")\n",
    "indices_train = indices_train[:, 0]\n",
    "indices_test = indices_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f6e8b-87fa-4ce3-80da-c9a51e03f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binarized = utils.binarize_labels_torch(y_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1279f89-ac36-4bb3-8b54-7226cf62a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique[\"label\"] = y_binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d007a-ee4f-4538-831c-07a9ae851873",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df_unique.rename(columns={\"text\": \"inputs\"})\n",
    "df_reduced = df_reduced.drop(columns=[\"id\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc7a86-a94f-425d-b410-dfe5bde3fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset = datasets.Dataset.from_pandas(df_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d583d8-0878-4020-b5b1-889419dddac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_func(x):\n",
    "    return tokenizer(x[\"inputs\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20736df-0c06-4cd4-84af-ab4b7551f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = _dataset.map(tok_func, batched=True, remove_columns=\"inputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e25ecd-4303-4b2d-8f0a-5a984043258a",
   "metadata": {},
   "source": [
    "### Convert dataset to object readable by `transformers.trainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b49e7-559d-476b-8a38-ed23af0a71ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training = datasets.DatasetDict(\n",
    "    {\n",
    "        \"train\": tokenized_dataset.select(indices_train),\n",
    "        \"test\": tokenized_dataset.select(indices_test),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97547f2c-d415-4354-887c-6cf92262edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dds(df, train=True):\n",
    "    ds = datasets.Dataset.from_pandas(df)\n",
    "    to_remove = [\"label\"]\n",
    "    tok_ds = ds.map(tok_func, batched=True, remove_columns=to_remove)\n",
    "    if train:\n",
    "        return datasets.DatasetDict(\n",
    "            {\n",
    "                \"train\": tok_ds.select(indices_train),\n",
    "                \"test\": tok_ds.select(indices_test),\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        return tok_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29758c-a5c3-42ea-b4b6-8edfb01ccbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_gpus():\n",
    "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\n",
    "\n",
    "    Defined in :numref:`sec_use_gpu`\"\"\"\n",
    "    devices = [torch.device(f\"cuda:{i}\") for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device(\"cpu\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b94dab-1720-4985-99e8-2b80c68e56cc",
   "metadata": {},
   "source": [
    "## Setting hyperparameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab663e-df6d-40a7-a698-56064cae6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-05\n",
    "train_batch_size = 4\n",
    "eval_batch_size = 4\n",
    "weight_decay = 0\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ca1ba-506d-4d88-bea9-206b641e51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(preds):\n",
    "    return {\n",
    "        \"log loss\": sklearn.metrics.log_loss(\n",
    "            preds.label_ids,\n",
    "            torch.nn.functional.softmax(torch.Tensor(preds.predictions)),\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5162705e-9be4-4f78-9e7c-00735bb680bc",
   "metadata": {},
   "source": [
    "## Defining trainer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00939377-d8f5-43e2-a5dc-aeee7846673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_scheduler_type='cosine' --> linear\n",
    "num_labels = 2\n",
    "\n",
    "\n",
    "def get_trainer(dds, tokenizer, finetuning=True):\n",
    "    \"\"\"gets trainer object, finetuning fixes parameters in the model to and only sets parameters of the classifier part to trainable\"\"\"\n",
    "    args = transformers.TrainingArguments(\n",
    "        \"/p/project/deepacf/maelstrom/ehlert1/output_RedditSentimentMultiLabelClassificationTransformerBaseline/\",\n",
    "        learning_rate=learning_rate,\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        fp16=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=train_batch_size,\n",
    "        per_device_eval_batch_size=eval_batch_size,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=weight_decay,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    model = transformers.AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=2)\n",
    "    if finetuning:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "    return transformers.Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=dds[\"train\"],\n",
    "        eval_dataset=dds[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=score,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0e705-c1ed-40ce-95ed-5cf799633cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27d350f-fc27-40d4-a7a6-d5acd06b473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = get_trainer(dataset_training, tokenizer, finetuning=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3e3968-256f-481a-8c44-1bbca57f934b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c33202-e84a-4693-993c-10c3c55a79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8232d58a-c509-4c1e-9d74-305b9d890720",
   "metadata": {},
   "source": [
    "## Check trainable and non-trainable parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bebadb-f823-4e3d-99fc-09dd2657fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"total number of parameters: {sum([p.numel() for p in trainer.model.parameters()])}, trainable parameters: {sum([p.numel() for p in trainer.model.parameters() if p.requires_grad])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaea441-0c1a-4c82-8ea5-d9dde6faec25",
   "metadata": {},
   "source": [
    "## Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2854b25b-6515-46e5-9502-71dc29da4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = get_dds(df_reduced.iloc[indices_test], train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f579f36-de1b-4d53-b7da-47435ce49f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.nn.functional.softmax(torch.Tensor(trainer.predict(test_ds).predictions)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c285d-0432-4dd5-bd6d-f69d960ddd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pytorch_indices_to_scikitlearn(y):\n",
    "    # [0, 1, 0] -> [[0,1],[0,1],[1,0]\n",
    "    y_new = np.zeros((y.shape[0], 2))\n",
    "    y_new[y == 1, 1] = 1\n",
    "    y_new[y == 0, 0] = 1\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d351306-de1b-4688-85d4-8dae50f06ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate = dict()\n",
    "true_positive_rate = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_labels):\n",
    "    (\n",
    "        false_positive_rate[i],\n",
    "        true_positive_rate[i],\n",
    "        _,\n",
    "    ) = sklearn.metrics.roc_curve(\n",
    "        convert_pytorch_indices_to_scikitlearn(df_reduced.iloc[indices_test].label.values)[:, i],\n",
    "        preds[:, i],\n",
    "    )\n",
    "    roc_auc[i] = sklearn.metrics.auc(false_positive_rate[i], true_positive_rate[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860199e5-ffac-414c-b20f-99fb0c7f738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "for i in range(num_labels):\n",
    "    plt.plot(\n",
    "        false_positive_rate[i],\n",
    "        true_positive_rate[i],\n",
    "        lw=lw,\n",
    "        label=\"ROC curve (area = %0.2f) for %i\" % (roc_auc[i], i),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c98afe-8cf3-4e86-815e-11481a6bc5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    sklearn.metrics.classification_report(\n",
    "        df_reduced.iloc[indices_test].label.values,\n",
    "        preds.argmax(-1),\n",
    "        target_names=[\"emotional\", \"neutral\"],\n",
    "        digits=4,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4228dca-4614-49df-b204-465402d07f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(df_reduced.iloc[indices_test].label.values, preds.argmax(-1))\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"emotional\", \"neutral\"])\n",
    "disp.plot()\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis=\"x\", labelrotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc66fb5-0110-4416-8979-81922cc4a79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
