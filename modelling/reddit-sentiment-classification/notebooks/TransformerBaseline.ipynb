{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754c4415-ff46-49af-87b5-8746997f0a70",
   "metadata": {},
   "source": [
    "# Training deBERTa (small version) classifier for sentimental analysis of Reddit data\n",
    "Training a deep learning model (deBERTa) that is based on the transformer architecture as part of the BERT encoder, which lies at the heart of the model. The model and pre-trained weights taken from [hugging face](https://huggingface.co/microsoft/deberta-v3-small). deBerta is generally proposed in [this paper](https://arxiv.org/abs/2006.03654). Here, we take the smallest model from the [repo of microsoft/deberta-v3-small](https://huggingface.co/microsoft/deberta-v3-small/tree/main). \n",
    "\n",
    "Results:\n",
    "- f1 score   macro avg: 0.73\n",
    "- f1 score  weighted avg: 0.78\n",
    "\n",
    "Note (from [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)):\n",
    "- F1 = 2 * (precision * recall) / (precision + recall)\n",
    "- 'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "- 'macro': Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "\n",
    "Also varied hyperparameters, which had no real impact on results (probing large parameter space may be required)\n",
    "- learning rate/10 (0.73, 0.78)\n",
    "- weight decay *10 (0.73, 0.78)\n",
    "\n",
    "Note (from [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)):\n",
    "- F1 = 2 * (precision * recall) / (precision + recall)\n",
    "- 'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "- 'macro': Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "\n",
    "Model weights: \\\n",
    "Weights need to be downloaded from the [repo of microsoft/deberta-v3-small](https://huggingface.co/microsoft/deberta-v3-small/tree/main) and put in the folder of execution to use them.\n",
    "\n",
    "Data:\\\n",
    "Data is downloaded when the notebook is executed from hugging face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea967c4d-7e76-4169-a512-54f17773de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://www.kaggle.com/code/tanlikesmath/feedback-prize-effectiveness-eda-deberta-baseline/notebook\n",
    "# transformers taken from https://huggingface.co/microsoft/deberta-v3-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16846587-c414-4b19-898b-f319fad78afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "import datasets\n",
    "\n",
    "import skmultilearn.model_selection.iterative_stratification\n",
    "import sklearn.metrics\n",
    "\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c481aa-5cd5-4e28-84f2-45abd147cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # empties gpu memory, may be required when interrupting training due bugs/user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a976e-41cd-4c19-91b2-8c037de9abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = (\n",
    "    \"/p/project/deepacf/maelstrom/ehlert1/deberta-v3-small\"  # model repo downloaded from hugging face see link above\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c4ec5c-bda5-4945-ba30-426068504c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /p/project/deepacf/maelstrom/ehlert1/deberta-v3-small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a094df-c424-4718-9d2d-49ea9ae8cf6b",
   "metadata": {},
   "source": [
    "## Tokenize data with same tokenizer used for pre-training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f394a-d71d-4dd4-a6ee-7f0a27de5991",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ddb325-7fd0-4cce-9602-ed33f572315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "separator_token = tokenizer.sep_token\n",
    "separator_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cead5a-bf08-4bfb-a4f9-caba6e07567a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a77cd1-8763-419a-b1f5-61710c0d2af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 28\n",
    "emotions = datasets.load_dataset(\"go_emotions\", \"simplified\")\n",
    "df_raw = pd.concat(\n",
    "    [\n",
    "        emotions.data[\"train\"].table.to_pandas(),\n",
    "        emotions.data[\"validation\"].table.to_pandas(),\n",
    "        emotions.data[\"test\"].table.to_pandas(),\n",
    "    ]\n",
    ")\n",
    "y_raw = utils.convert_df_labels(df_raw, num_labels)\n",
    "df_unique = utils.remove_ambiguous_data(df_raw, y_raw)\n",
    "# updated data frame shape, therefore need to recompute y labels\n",
    "y_unique = utils.convert_df_labels(df_unique, num_labels)\n",
    "# explanation for iterative stratification of labels http://videolectures.net/ecmlpkdd2011_tsoumakas_stratification/?q=stratification%20multi%20label\n",
    "(\n",
    "    indices_train,\n",
    "    y_train,\n",
    "    indices_test,\n",
    "    y_test,\n",
    ") = skmultilearn.model_selection.iterative_stratification.iterative_train_test_split(\n",
    "    np.arange(df_unique.shape[0]).reshape(-1, 1), y_unique, 0.1\n",
    ")\n",
    "indices_train = indices_train[:, 0]\n",
    "indices_test = indices_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f6e8b-87fa-4ce3-80da-c9a51e03f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binarized = utils.binarize_labels_torch(y_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1279f89-ac36-4bb3-8b54-7226cf62a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique[\"label\"] = y_binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d007a-ee4f-4538-831c-07a9ae851873",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df_unique.rename(columns={\"text\": \"inputs\"})\n",
    "df_reduced = df_reduced.drop(columns=[\"id\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc7a86-a94f-425d-b410-dfe5bde3fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset = datasets.Dataset.from_pandas(df_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d583d8-0878-4020-b5b1-889419dddac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_func(x):\n",
    "    return tokenizer(x[\"inputs\"], truncation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20736df-0c06-4cd4-84af-ab4b7551f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_map = _dataset.map(tok_func, batched=True, remove_columns=\"inputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c2c954-0878-45a2-bb6c-ed5e12e57174",
   "metadata": {},
   "source": [
    "### Convert dataset to object readable by `transformers.trainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b49e7-559d-476b-8a38-ed23af0a71ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training = datasets.DatasetDict(\n",
    "    {\n",
    "        \"train\": tok_map.select(indices_train),\n",
    "        \"test\": tok_map.select(indices_test),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97547f2c-d415-4354-887c-6cf92262edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df, tok_func, train=True):\n",
    "    ds = datasets.Dataset.from_pandas(df)\n",
    "    to_remove = [\"label\"]\n",
    "    tok_ds = ds.map(tok_func, batched=True, remove_columns=to_remove)\n",
    "    if train:\n",
    "        return datasets.DatasetDict(\n",
    "            {\n",
    "                \"train\": tok_ds.select(indices_train),\n",
    "                \"test\": tok_ds.select(indices_test),\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        return tok_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29758c-a5c3-42ea-b4b6-8edfb01ccbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_gpus():\n",
    "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\n",
    "\n",
    "    Defined in :numref:`sec_use_gpu`\"\"\"\n",
    "    devices = [torch.device(f\"cuda:{i}\") for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device(\"cpu\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8749aa-c7a5-42e0-beca-137589f6c71e",
   "metadata": {},
   "source": [
    "## Setting hyperparameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab663e-df6d-40a7-a698-56064cae6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 8e-5\n",
    "batch_size = 8\n",
    "weight_decay = 0.01\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ca1ba-506d-4d88-bea9-206b641e51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(preds):\n",
    "    return {\n",
    "        \"log loss\": sklearn.metrics.log_loss(\n",
    "            preds.label_ids,\n",
    "            torch.nn.functional.softmax(torch.Tensor(preds.predictions)),\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27ae46-6afa-4480-b471-aef7298a1a79",
   "metadata": {},
   "source": [
    "## Defining trainer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00939377-d8f5-43e2-a5dc-aeee7846673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 2\n",
    "\n",
    "\n",
    "def get_trainer(dds, num_labels):\n",
    "    args = transformers.TrainingArguments(\n",
    "        \"/p/project/deepacf/maelstrom/ehlert1/output_RedditSentimentMultiLabelClassificationTransformerBaseline/\",\n",
    "        learning_rate=learning_rate,\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        fp16=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size * 2,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=weight_decay,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    model = transformers.AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=num_labels)\n",
    "    return transformers.Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=dds[\"train\"],\n",
    "        eval_dataset=dds[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=score,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0e705-c1ed-40ce-95ed-5cf799633cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_all_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e71c88-d9b7-41f4-a8c8-024296c98ec7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e298c0e6-e801-4f8f-b303-23456bfc9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = get_trainer(dataset_training, num_labels)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51af28d-4ced-40ab-9dd1-5eef3be4459d",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2854b25b-6515-46e5-9502-71dc29da4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = get_dataset(df_reduced.iloc[indices_test], tok_func, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f579f36-de1b-4d53-b7da-47435ce49f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.nn.functional.softmax(torch.Tensor(trainer.predict(test_ds).predictions)).numpy()\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c285d-0432-4dd5-bd6d-f69d960ddd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pytorch_indices_to_scikitlearn(y):\n",
    "    y_new = np.zeros((y.shape[0], 2))\n",
    "    y_new[y == 1, 1] = 1\n",
    "    y_new[y == 0, 0] = 1\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d351306-de1b-4688-85d4-8dae50f06ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate = dict()\n",
    "true_positive_rate = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_labels):\n",
    "    (\n",
    "        false_positive_rate[i],\n",
    "        true_positive_rate[i],\n",
    "        _,\n",
    "    ) = sklearn.metrics.roc_curve(\n",
    "        convert_pytorch_indices_to_scikitlearn(df_reduced.iloc[indices_test].label.values)[:, i],\n",
    "        preds[:, i],\n",
    "    )\n",
    "    roc_auc[i] = sklearn.metrics.auc(false_positive_rate[i], true_positive_rate[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860199e5-ffac-414c-b20f-99fb0c7f738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "for i in range(num_labels):\n",
    "    plt.plot(\n",
    "        false_positive_rate[i],\n",
    "        true_positive_rate[i],\n",
    "        lw=lw,\n",
    "        label=\"ROC curve (area = %0.2f) for %i\" % (roc_auc[i], i),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c98afe-8cf3-4e86-815e-11481a6bc5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    sklearn.metrics.classification_report(\n",
    "        df_reduced.iloc[indices_test].label.values,\n",
    "        preds.argmax(-1),\n",
    "        target_names=[\"emotional\", \"neutral\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4228dca-4614-49df-b204-465402d07f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(df_reduced.iloc[indices_test].label.values, preds.argmax(-1))\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"emotional\", \"neutral\"])\n",
    "disp.plot()\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis=\"x\", labelrotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc66fb5-0110-4416-8979-81922cc4a79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
