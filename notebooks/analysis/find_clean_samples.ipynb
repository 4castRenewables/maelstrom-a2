{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to identify a clean sample of Tweets and labels\n",
    "\n",
    "To validate a model for the classification of Tweets as \"raining\" or \"not raining\", the lack of data quality has been identified as a major obstacle. Therefore, we would like to identify a sample of Tweets, that\n",
    "- that provide sufficient information to be classified as \"raining\" / \"not raining\" (by human/machine/...)\n",
    "- are labeled as accurately as possible\n",
    "\n",
    "\n",
    "Results:\n",
    "\n",
    "- Use tweets that are near weather stations and use weather station measurements as labels\n",
    "- Optionally, use only Tweets that have a high prediction probability for their respective class (bit circular \"cleaning\" procedure which will introduce a bias... when evaluating models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows update of external libraries without need to reload package\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.manifold\n",
    "import gc\n",
    "import sys\n",
    "import guppy\n",
    "import tqdm\n",
    "import memory_profiler\n",
    "import torch\n",
    "import openTSNE\n",
    "import xarray\n",
    "import plotly\n",
    "\n",
    "import a2.training.training_hugging\n",
    "import a2.training.evaluate_hugging\n",
    "import a2.training.dataset_hugging\n",
    "import a2.plotting.analysis\n",
    "import a2.plotting.histograms\n",
    "import a2.dataset\n",
    "import a2.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_MODEL_PRETRAINED = \"../../models/model_weights/output_rainprediction_simpledeberta/era5/checkpoint-7617/\"\n",
    "FOLDER_MODEL = \"microsoft/deberta-v3-small\"\n",
    "# FILE_TWEETS = \"../../../maelstrom_bootcamp/Applications/AP2/bootcamp2022_data/tweets/tweets_2017_01_era5_normed_filtered.nc\"\n",
    "FOLDER_TWEETS = \"/home/kristian/Projects/a2/data/tweets/\"\n",
    "FILE_TWEETS = (\n",
    "    FOLDER_TWEETS\n",
    "    + \"2017_2020_tweets_rain_sun_vocab_emojis_locations_bba_Tp_era5_no_bots_normalized_filtered_weather_stations_fix_predicted_simpledeberta_radar.nc\"\n",
    ")\n",
    "FOLDER_EMBEDDINGS = \"/home/kristian/Projects/a2/data/embeddings/cls_token/\"\n",
    "FILE_EMBEDDINGS = FOLDER_EMBEDDINGS + \"cls_tokenstweets_2017_era5_normed_filtered.nc.npy\"\n",
    "!ls $FILE_TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_raw = a2.dataset.load_dataset.load_tweets_dataset(FILE_TWEETS)\n",
    "ds = ds_raw.where(ds_raw[\"created_at\"].dt.year != 2020, drop=True)\n",
    "ds[\"raining\"] = ([\"index\"], np.array(ds.tp_h.values > 1e-8, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.plotting.analysis.plot_prediction_certainty(ds[\"raining\"].values, ds[\"prediction_probability_raining\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"prediction_probability_raining\"].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_NR_TN = ds.where((ds[\"prediction_probability_raining\"] < 0.3) & (ds[\"raining\"] == 0), drop=True)\n",
    "ds_R_TP = ds.where((ds[\"prediction_probability_raining\"] > 0.8) & (ds[\"raining\"] == 1), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_undecided = ds.where(\n",
    "    (ds[\"prediction_probability_raining\"] > 0.4) & (ds[\"prediction_probability_raining\"] < 0.6), drop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"raining_station\"] = ([\"index\"], ds[\"station_tp_mm\"].values > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = 0.12\n",
    "a2.plotting.histograms.plot_histogram_2d(\n",
    "    x=\"station_distance_km\",\n",
    "    y=\"prediction_probability_raining\",\n",
    "    ds=df,\n",
    "    # facet_column='raining',\n",
    "    facet_row=\"raining_station\",\n",
    "    n_bins=[40, 40],\n",
    "    xlim=[0, 3],\n",
    "    ylim=[0, 1],\n",
    "    spacing_x=spacing,\n",
    "    spacing_y=spacing,\n",
    "    font_size=10,\n",
    "    filename=\"/tmp/test.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.express.density_heatmap(\n",
    "    df,\n",
    "    x=\"station_distance_km\",\n",
    "    y=\"prediction_probability_raining\",\n",
    "    facet_col=\"raining\",\n",
    "    facet_row=\"raining_station\",\n",
    "    nbinsx=400,\n",
    "    nbinsy=100,\n",
    "    range_x=[0, 3],\n",
    "    range_y=[0, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_near_station = ds.where(\n",
    "    (ds[\"station_distance_km\"] < 1) & (~a2.dataset.utils_dataset.is_nan(ds, \"station_tp_mm\")), drop=True\n",
    ")\n",
    "ds_near_station.index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_near_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_near_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.plotting.histograms.plot_histogram_2d(\n",
    "    ds=ds_near_station, y=\"raining_station\", x=\"station_tp_mm\", xlim=[0, 1], norm=\"log\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.dataset.load_dataset.save_dataset(ds_near_station, \"../../data/tweets/2017_2020_tweets_keywords_near_station.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_near_station.where(ds_near_station[\"station_tp_mm\"] == 1, drop=True)[[\"text\", \"text_normalized\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_near_station[\"station_tp_mm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = a2.plotting.analysis.classification_report(\n",
    "    ds_near_station[\"raining_station\"].values, ds_near_station[\"raining\"], output_dict=False\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = a2.plotting.analysis.classification_report(\n",
    "    ds_near_station[\"raining_station\"].values,\n",
    "    ds_near_station[\"prediction_probability_raining\"].values > 0.8,\n",
    "    output_dict=False,\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.plotting.histograms.plot_histogram(\n",
    "    ds_near_station.where(~a2.dataset.utils_dataset.is_na(ds_near_station, \"full_name\"), drop=True)[\"full_name\"].values,\n",
    "    log=[False, False],\n",
    "    min_counts=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.plotting.histograms.plot_histogram(ds_near_station[\"bounding_box_area\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.where(\n",
    "    (ds[\"raining_station\"] == 1) & (ds[\"raining\"] == 0) & (ds[\"prediction_probability_raining\"] > 0.8), drop=True\n",
    ").text.values[100:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_near_station.text_normalized.values[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_near_station.where(\n",
    "    (ds_near_station[\"raining_station\"] == 1) & (ds_near_station[\"prediction_probability_raining\"] > 0.8), drop=True\n",
    ").text_normalized.values[100:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_near_station.where(\n",
    "    (ds_near_station[\"raining_station\"] == 0) & (ds_near_station[\"prediction_probability_raining\"] < 0.2), drop=True\n",
    ").text_normalized.values[100:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.plotting.analysis.plot_prediction_certainty(\n",
    "    ds_near_station[\"raining_station\"].values, ds_near_station[\"prediction_probability_raining\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.plotting.histograms.plot_histogram_2d(\n",
    "    ds[\"station_distance_km\"].values, ds[\"raining_station\"].values - ds[\"raining\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $FOLDER_TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download an instagram photo or video\n",
    "import re\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def download_image_video(url):\n",
    "\n",
    "    x = re.match(r\"^(https:)[/][/]www.([^/]+[.])*instagram.com\", url)\n",
    "\n",
    "    # try:\n",
    "    if x:\n",
    "        request_image = requests.get(url)\n",
    "        return request_image\n",
    "        src = request_image.content.decode(\"utf-8\")\n",
    "        check_type = re.search(r'<meta name=\"medium\" content=[\\'\"]?([^\\'\" >]+)', src)\n",
    "        check_type_f = check_type.group()\n",
    "        final = re.sub('<meta name=\"medium\" content=\"', \"\", check_type_f)\n",
    "\n",
    "        if final == \"image\":\n",
    "            print(\"\\nDownloading the image...\")\n",
    "            extract_image_link = re.search(r'meta property=\"og:image\" content=[\\'\"]?([^\\'\" >]+)', src)\n",
    "            print(f\"{extract_image_link=}\")\n",
    "            image_link = extract_image_link.group()\n",
    "            print(f\"{image_link=}\")\n",
    "            final = re.sub('meta property=\"og:image\" content=\"', \"\", image_link)\n",
    "            print(f\"{final=}\")\n",
    "            _response = requests.get(final).content\n",
    "            file_size_request = requests.get(final, stream=True)\n",
    "            file_size = int(file_size_request.headers[\"Content-Length\"])\n",
    "            block_size = 1024\n",
    "            filename = datetime.strftime(datetime.now(), \"%Y-%m-%d-%H-%M-%S\")\n",
    "            t = tqdm(total=file_size, unit=\"B\", unit_scale=True, desc=filename, ascii=True)\n",
    "            with open(filename + \".jpg\", \"wb\") as f:\n",
    "                for data in file_size_request.iter_content(block_size):\n",
    "                    t.update(len(data))\n",
    "                    f.write(data)\n",
    "            t.close()\n",
    "            print(\"Image downloaded successfully\")\n",
    "\n",
    "        if final == \"video\":\n",
    "            msg = input(\"You are trying to download a video. Do you want to continue? (Yes or No): \".lower())\n",
    "\n",
    "            if msg == \"yes\":\n",
    "                print(\"Downloading the video...\")\n",
    "                extract_video_link = re.search(r'meta property=\"og:video\" content=[\\'\"]?([^\\'\" >]+)', src)\n",
    "                video_link = extract_video_link.group()\n",
    "                final = re.sub('meta property=\"og:video\" content=\"', \"\", video_link)\n",
    "                _response = requests.get(final).content\n",
    "                file_size_request = requests.get(final, stream=True)\n",
    "                file_size = int(file_size_request.headers[\"Content-Length\"])\n",
    "                block_size = 1024\n",
    "                filename = datetime.strftime(datetime.now(), \"%Y-%m-%d-%H-%M-%S\")\n",
    "                t = tqdm(total=file_size, unit=\"B\", unit_scale=True, desc=filename, ascii=True)\n",
    "                with open(filename + \".mp4\", \"wb\") as f:\n",
    "                    for data in file_size_request.iter_content(block_size):\n",
    "                        t.update(len(data))\n",
    "                        f.write(data)\n",
    "                t.close()\n",
    "                print(\"Video downloaded successfully\")\n",
    "\n",
    "            if msg == \"no\":\n",
    "                exit()\n",
    "    else:\n",
    "        print(\"Entered URL is not an instagram.com URL.\")\n",
    "    return src\n",
    "    # except AttributeError:\n",
    "    # print(\"Unknown URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = download_image_video(\"https://www.instagram.com/p/BVAiK6OFwpK/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.raw.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(src.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.findall(r'meta property=\"og:image\" content=[\\'\"]?([^\\'\" >]+)', src)#.group()\n",
    "re.findall(r\"object-fit\", src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://scontent-ham3-1.cdninstagram.com/v/t51.2885-15/18809724_1881045368817923_3546898024418508800_n.jpg?stp=dst-jpg_e35&_nc_ht=scontent-ham3-1.cdninstagram.com&_nc_cat=111&_nc_ohc=WyPCirPVV9EAX86Rbc1&edm=AP_V10EBAAAA&ccb=7-5&oh=00_AfDG28DzonjDkkXHYM68Ehig_t7N77RWLI_HmCBhb8kycg&oe=6402FE9F&_nc_sid=4f375e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(\"2023-02-28-16-20-19.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "06c3f19a037da30281d10f8fbda7f2df02465bd919ed005b52297a6fc2623835"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
