{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Tweets based on their embeddings \n",
    "\n",
    "- Retrieve embeddings from finetuned DeBERTa model for Tweets\n",
    "- Cluster Tweets with `sklearn.manifold.TSNE` in both 2D and 3D\n",
    "- Visualize results\n",
    "- Results:\n",
    "    - Clustering provides only limited additinal information. \n",
    "    - Small clusters can be identified by hand with topics not related to rain classification (e.g. \"holidays\")\n",
    "    - However, clustering algorithm results vary based on parameters and random initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows update of external libraries without need to reload package\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.manifold\n",
    "import gc\n",
    "import sys\n",
    "import guppy\n",
    "import tqdm\n",
    "import memory_profiler\n",
    "import torch\n",
    "import openTSNE\n",
    "import xarray\n",
    "\n",
    "import a2.training.training_hugging\n",
    "import a2.training.evaluate_hugging\n",
    "import a2.training.dataset_hugging\n",
    "import a2.dataset\n",
    "import a2.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_MODEL_PRETRAINED = \"../../models/model_weights/output_rainprediction_simpledeberta/era5/checkpoint-7617/\"\n",
    "FOLDER_MODEL = \"microsoft/deberta-v3-small\"\n",
    "# FILE_TWEETS = \"../../../maelstrom_bootcamp/Applications/AP2/bootcamp2022_data/tweets/tweets_2017_01_era5_normed_filtered.nc\"\n",
    "FOLDER_TWEETS = \"/home/kristian/Projects/a2/data/tweets/\"\n",
    "FILE_TWEETS = FOLDER_TWEETS + \"tweets_2017_era5_normed_filtered_predicted_simpledeberta.nc\"\n",
    "FOLDER_EMBEDDINGS = \"/home/kristian/Projects/a2/data/embeddings/cls_token/\"\n",
    "FILE_EMBEDDINGS = FOLDER_EMBEDDINGS + \"cls_tokenstweets_2017_era5_normed_filtered.nc.npy\"\n",
    "!ls $FILE_TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = a2.dataset.load_dataset.load_tweets_dataset(FILE_TWEETS)\n",
    "ds[\"raining\"] = ([\"index\"], np.array(ds.tp_h.values > 1e-8, dtype=int))  # above numerical noise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cls token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cls_representation(\n",
    "    ds: xarray.Dataset,\n",
    "    folder_tokenizer: str,\n",
    "    folder_model: str,\n",
    "    key_label: str = \"raining\",\n",
    "    key_inputs: str = \"text_normalized\",\n",
    "):\n",
    "    (\n",
    "        indices_train,\n",
    "        indices_validate,\n",
    "    ) = a2.training.training_hugging.split_training_set(ds, key_stratify=key_label, test_size=0.2)\n",
    "\n",
    "    dataset_spawner = a2.training.dataset_hugging.DatasetHuggingFace(folder_tokenizer)\n",
    "    dataset = dataset_spawner.build(\n",
    "        ds,\n",
    "        indices_train=indices_train,\n",
    "        indices_validate=indices_validate,\n",
    "        train=False,\n",
    "        key_inputs=key_inputs,\n",
    "        key_label=key_label,\n",
    "    )\n",
    "\n",
    "    trainer_spawner = a2.training.training_hugging.HuggingFaceTrainerClass(folder_model, num_labels=2)\n",
    "    trainer = trainer_spawner.get_trainer(\n",
    "        dataset,\n",
    "        tokenizer=dataset_spawner.tokenizer,\n",
    "        evaluate=True,\n",
    "        mantik=False,\n",
    "        fp16=False,\n",
    "    )\n",
    "\n",
    "    model = trainer.model\n",
    "    model = model.eval()\n",
    "\n",
    "    def get_batch(dataset_spawner, i_start, i_end, model):\n",
    "        inputs = dataset_spawner.tokenizer(\n",
    "            ds[key_inputs].values.tolist()[i_start : i_end + 1],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            last_hidden_states = outputs.hidden_states[-1]\n",
    "            del outputs, inputs, model\n",
    "            return last_hidden_states[:, 0, :]\n",
    "\n",
    "    cls_representations = []\n",
    "    indices = np.arange(ds[\"index\"].shape[0])\n",
    "    n_per_batch = max([len(indices) // 1000, 1])\n",
    "    for indices_batch in tqdm.tqdm(np.array_split(indices, n_per_batch)):\n",
    "        i_start, i_end = indices_batch[0], indices_batch[-1]\n",
    "        batch = get_batch(dataset_spawner, i_start, i_end, model)\n",
    "        gc.collect()\n",
    "        cls_representations.extend(batch)\n",
    "    return np.array([x.detach().numpy() for x in cls_representations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = np.arange(100)\n",
    "for x in np.array_split(ar, 9):\n",
    "    print(ar[x[0] : x[-1] + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array_split(np.arange(20), 100)[-1]\n",
    "x[0], x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 10000\n",
    "ds_test = ds.sel(index=slice(n_sample))\n",
    "indices_validate = np.arange(ds_test.index.shape[0])\n",
    "\n",
    "(truth, predictions, prediction_probabilities,) = a2.training.evaluate_hugging.make_predictions_loaded_model(\n",
    "    ds_test,\n",
    "    indices_validate=indices_validate,\n",
    "    folder_model=FOLDER_MODEL_PRETRAINED,\n",
    "    folder_tokenizer=FOLDER_MODEL,\n",
    "    key_inputs=\"text_normalized\",\n",
    "    fp16=False,\n",
    ")\n",
    "ds_test = a2.training.evaluate_hugging.build_ds_test(ds_test, indices_validate, predictions, prediction_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_tokens = get_cls_representation(\n",
    "    ds_test,\n",
    "    folder_tokenizer=FOLDER_MODEL,\n",
    "    folder_model=FOLDER_MODEL_PRETRAINED,\n",
    "    key_label=\"raining\",\n",
    "    key_inputs=\"text_normalized\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_tokens.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"ds_test_{n_sample}_tokens.npy\", cls_tokens)\n",
    "ds_test.to_netcdf(f\"ds_test_{n_sample}.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = sklearn.manifold.TSNE(init=\"pca\", learning_rate=\"auto\", n_iter=5000, perplexity=200, n_jobs=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = tsne.fit_transform(cls_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(ds: xarray.Dataset, key: str, end: int = n_sample + 1):\n",
    "    return ds[key].values[:end]\n",
    "\n",
    "\n",
    "hover_keys = [\"text_normalized\", \"raining\", \"prediction_probability_raining\"]\n",
    "fig = plotly.express.scatter(\n",
    "    data_frame=ds_test.to_dataframe(),\n",
    "    x=projections.T[0],\n",
    "    y=projections.T[1],\n",
    "    # color=\"difference_prediction\",\n",
    "    hover_data=hover_keys,\n",
    "    facet_col=\"raining\",\n",
    "    color_continuous_scale=\"Aggrnyl\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test[\"difference_prediction\"] = (\n",
    "    [\"index\"],\n",
    "    np.abs(ds_test.prediction_probability_raining.values - ds_test.raining.values),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017 Tweets\n",
    "(downloaded from juwels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = a2.dataset.load_dataset.load_tweets_dataset(FILE_TWEETS)\n",
    "ds[\"raining\"] = ([\"index\"], np.array(ds.tp_h.values > 1e-8, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = np.load(\n",
    "    \"/home/kristian/Projects/a2/data/clustering/projections_initrandom_perplexity50tweets_2017_era5_normed_filtered.nc.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hover_keys = [\"text_normalized\", \"raining\"]\n",
    "mask = a2.utils.utils.get_random_indices(10000, ds.index.shape[0])\n",
    "fig = plotly.express.scatter(\n",
    "    data_frame=ds.sel(index=mask).to_dataframe(),\n",
    "    x=projections[mask].T[0],\n",
    "    y=projections[mask].T[1],\n",
    "    color=\"prediction_probability_raining\",\n",
    "    hover_data=hover_keys,\n",
    "    facet_col=\"raining\",\n",
    "    color_continuous_scale=\"Aggrnyl\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_3d = sklearn.manifold.TSNE(n_components=3, init=\"pca\", learning_rate=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections_3d = tsne_3d.fit_transform(cls_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(ds: xarray.Dataset, key: str, end: int = n_sample + 1):\n",
    "    return ds[key].values[:end]\n",
    "\n",
    "\n",
    "hover_keys = [\"text_normalized\", \"raining\", \"prediction_probability_raining\"]\n",
    "fig = plotly.express.scatter_3d(\n",
    "    data_frame=ds_test.to_dataframe(),\n",
    "    x=projections_3d.T[0],\n",
    "    y=projections_3d.T[1],\n",
    "    z=projections_3d.T[2],\n",
    "    color=\"difference_prediction\",\n",
    "    hover_data=hover_keys,\n",
    "    size_max=1,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.where(\n",
    "    ~a2.dataset.utils_dataset.is_nan(ds, \"geo.coordinates.coordinates\"),\n",
    "    drop=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.latitude_rounded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using opentsne\n",
    "Alternative implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_tokens = np.load(FILE_EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 10000\n",
    "exaggeration = 1\n",
    "perplexity = 50\n",
    "mask = a2.utils.utils.get_random_indices(n_sample, ds.index.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = openTSNE.TSNE(\n",
    "    n_jobs=14,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    "    perplexity=perplexity,\n",
    "    exaggeration=exaggeration,\n",
    ")\n",
    "projections = tsne.fit(cls_tokens[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hover_keys = [\"text_normalized\", \"raining\"]\n",
    "fig = plotly.express.scatter(\n",
    "    data_frame=ds.sel(index=mask).to_dataframe(),\n",
    "    x=projections.T[0],\n",
    "    y=projections.T[1],\n",
    "    color=\"prediction_probability_raining\",\n",
    "    hover_data=hover_keys,\n",
    "    facet_col=\"raining\",\n",
    "    color_continuous_scale=\"Aggrnyl\",\n",
    "    width=1000,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(f\"tsne_{n_sample}_perplex{perplexity}_exaggeration{exaggeration}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "06c3f19a037da30281d10f8fbda7f2df02465bd919ed005b52297a6fc2623835"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
