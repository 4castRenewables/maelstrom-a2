{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows update of external libraries without need to reload package\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import transformers\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "LIBRARY_PATH = \"/p/project/deepacf/maelstrom/ehlert1/a2/src/\"\n",
    "sys.path.append(LIBRARY_PATH)\n",
    "import a2.training.training_hugging\n",
    "import a2.training.evaluate_hugging\n",
    "import a2.training.dataset_hugging\n",
    "import a2.plotting.analysis\n",
    "import a2.plotting.histograms\n",
    "import a2.dataset\n",
    "import a2.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.training.utils_training.gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FOLDER_MODELS = a2.utils.file_handling.get_folder_models()\n",
    "FOLDER_MODEL_PRETRAINED = (\n",
    "    BASE_FOLDER_MODELS / \"/model_weights/output_rainprediction_simpledeberta/era5/checkpoint-7617/\"\n",
    ")\n",
    "FOLDER_MODEL = BASE_FOLDER_MODELS / \"llama-13b-hf\"\n",
    "FOLDER_TWEETS = a2.utils.file_handling.get_folder_data() / \"tweets/\"\n",
    "FILE_TWEETS = FOLDER_TWEETS / \"2017_2020_tweets_keywords_near_station.nc\"\n",
    "FOLDER_EMBEDDINGS = \"/home/kristian/Projects/a2/data/embeddings/cls_token/\"\n",
    "FILE_EMBEDDINGS = FOLDER_EMBEDDINGS + \"cls_tokenstweets_2017_era5_normed_filtered.nc.npy\"\n",
    "!ls $FILE_TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = a2.dataset.load_dataset.load_tweets_dataset(FILE_TWEETS)\n",
    "ds[\"raining\"] = ([\"index\"], np.array(ds.station_tp_mm.values > 0, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $FOLDER_MODEL/tokenizer_config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(FOLDER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.LlamaForCausalLM.from_pretrained(FOLDER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r'Assign a probability that it is raining to the following tweets. The content of the tweets should hint something about the weather being rainy and not good in general. Tweet 1: \"Well that last rumble of thunder made the house shake, I wasn\\'t scared for a couple of seconds\" Tweet 2: \"#viewfromthe office what a great morning @Grantham and District\". Return the results in a json file like: [ { \"tweet\": 1, \"content\": \"Well that last rumble of thunder made the house shake, I wasn\\'t scared for a couple of seconds\", \"explanation\": \"short explanation of the rain probability based on content of this tweet\", \"rain_probability\": x.x }, ... ] Result: [ { \"tweet\": 1, \"content\":'\n",
    "text = r\"\"\"Assign a probability that it is raining to the following tweets. The content of the tweets should hint something about the weather being rainy and not good in general. \n",
    "Tweet 1: \"The sound of rain tapping on the window\" \n",
    "Tweet 2: \"Boris seems desperate for the rain to finish\". \n",
    "Return the results in a json file like: [ { \"tweet\": 1, \"content\": \"The sound of rain tapping on the window\", \"explanation\": \"The sound of rain heard implies that is raining.\", \"rain_probability\": 0.9 }, ... ] \n",
    "Result: [ { \"tweet\": 1, \"content\":\"\"\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "sample_outputs = model.generate(\n",
    "    input_ids,\n",
    "    temperature=0.2,\n",
    "    do_sample=True,\n",
    "    max_length=400,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=3,\n",
    "    early_stopping=True,\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * \"-\")\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?model.prepare_inputs_for_generation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
