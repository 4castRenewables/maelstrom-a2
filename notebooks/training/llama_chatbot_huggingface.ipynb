{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows update of external libraries without need to reload package\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import transformers\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "LIBRARY_PATH = \"/p/project/deepacf/maelstrom/ehlert1/a2/src/\"\n",
    "sys.path.append(LIBRARY_PATH)\n",
    "import a2.training.training_hugging\n",
    "import a2.training.evaluate_hugging\n",
    "import a2.training.dataset_hugging\n",
    "import a2.plotting.analysis\n",
    "import a2.plotting.histograms\n",
    "import a2.dataset\n",
    "import a2.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.training.utils_training.gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/p/scratch/deepacf/maelstrom/maelstrom_data/ap2/data/tweets/2017_2020_tweets_keywords_near_station.nc\n"
     ]
    }
   ],
   "source": [
    "BASE_FOLDER_MODELS = a2.utils.file_handling.get_folder_models()\n",
    "FOLDER_MODEL_PRETRAINED = BASE_FOLDER_MODELS / \"/model_weights/output_rainprediction_simpledeberta/era5/checkpoint-7617/\"\n",
    "FOLDER_MODEL = BASE_FOLDER_MODELS / \"llama-13b-hf\"\n",
    "FOLDER_TWEETS = a2.utils.file_handling.get_folder_data() / \"tweets/\"\n",
    "FILE_TWEETS = FOLDER_TWEETS / \"2017_2020_tweets_keywords_near_station.nc\"\n",
    "FOLDER_EMBEDDINGS = \"/home/kristian/Projects/a2/data/embeddings/cls_token/\"\n",
    "FILE_EMBEDDINGS = FOLDER_EMBEDDINGS + \"cls_tokenstweets_2017_era5_normed_filtered.nc.npy\"\n",
    "!ls $FILE_TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = a2.dataset.load_dataset.load_tweets_dataset(FILE_TWEETS)\n",
    "ds[\"raining\"] = ([\"index\"], np.array(ds.station_tp_mm.values > 0, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"bos_token\": \"\", \"eos_token\": \"\", \"model_max_length\": 1000000000000000019884624838656, \"tokenizer_class\": \"LlamaTokenizer\", \"unk_token\": \"\"}"
     ]
    }
   ],
   "source": [
    "!cat $FOLDER_MODEL/tokenizer_config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.29.0.dev0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(FOLDER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3f7dbf0547417dae6b2e853116b536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = transformers.LlamaForCausalLM.from_pretrained(FOLDER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: Assign a probability that it is raining to the following tweets. The content of the tweets should hint something about the weather being rainy and not good in general. \n",
      "Tweet 1: \"The sound of rain tapping on the window\" \n",
      "Tweet 2: \"Boris seems desperate for the rain to finish\". \n",
      "Return the results in a json file like: [ { \"tweet\": 1, \"content\": \"The sound of rain tapping on the window\", \"explanation\": \"The sound of rain heard implies that is raining.\", \"rain_probability\": 0.9 }, ... ] \n",
      "Result: [ { \"tweet\": 1, \"content\": \"The sound of rain tapping on the window\", \"explanation\": \"The sound of rain heard implies that is raining.\", \"rain_probability\": 0.9 }, { \"tweet\": 2, \"content\": \"Boris seems desperate for the rain to finish\", \"explanation\": \"Boris seems desperate for the rain to finish implies that it is raining.\", \"rain_probability\": 0.8 } ]\n",
      "\"\"\"\n",
      "\n",
      "import re\n",
      "import json\n",
      "import sys\n",
      "import os\n",
      "\n",
      "\n",
      "def get_tweets():\n",
      "    \"\"\"\n",
      "    Get the tweets from the file.\n",
      "    \"\"\"\n",
      "    tweets = []\n",
      "    with open(sys.argv[1]) as f:\n",
      "        for line in f:\n",
      "            tweets.append(line.strip())\n",
      "    return tweets\n",
      "\n",
      "\n",
      "def get_content(tweet):\n",
      "    \"\"\"\n",
      "    Get the content from the tweet.\n",
      "    \"\"\"\n",
      "    content = re.search(r\"^.*?\\b(\\w+)\\b.*$\", tweet)\n",
      "    if content:\n",
      "        return content.group\n",
      "1: Assign a probability that it is raining to the following tweets. The content of the tweets should hint something about the weather being rainy and not good in general. \n",
      "Tweet 1: \"The sound of rain tapping on the window\" \n",
      "Tweet 2: \"Boris seems desperate for the rain to finish\". \n",
      "Return the results in a json file like: [ { \"tweet\": 1, \"content\": \"The sound of rain tapping on the window\", \"explanation\": \"The sound of rain heard implies that is raining.\", \"rain_probability\": 0.9 }, ... ] \n",
      "Result: [ { \"tweet\": 1, \"content\": \"The sound of rain tapping on the window\", \"explanation\": \"The sound of rain heard implies that is raining.\", \"rain_probability\": 0.9 }, { \"tweet\": 2, \"content\": \"Boris seems desperate for the rain to finish\", \"explanation\": \"The rain is not good for Boris.\", \"rain_probability\": 0.8 } ]\n",
      "\"\"\"\n",
      "\n",
      "import re\n",
      "import json\n",
      "import sys\n",
      "\n",
      "\n",
      "def get_tweets():\n",
      "    tweets = []\n",
      "    with open('tweets.txt', 'r') as f:\n",
      "        for line in f:\n",
      "            tweets.append(line.strip())\n",
      "    return tweets\n",
      "\n",
      "\n",
      "def get_tweet_probabilities(tweets):\n",
      "    probabilities = {}\n",
      "    for tweet in tweets:\n",
      "        tweet_probabilities = {}\n",
      "        for tweet_probability in tweet.split():\n",
      "            tweet_probabilities[tweet_probability] = float(tweet_probability)\n",
      "        probabilities[tweet] = tweet\n",
      "2: Assign a probability that it is raining to the following tweets. The content of the tweets should hint something about the weather being rainy and not good in general. \n",
      "Tweet 1: \"The sound of rain tapping on the window\" \n",
      "Tweet 2: \"Boris seems desperate for the rain to finish\". \n",
      "Return the results in a json file like: [ { \"tweet\": 1, \"content\": \"The sound of rain tapping on the window\", \"explanation\": \"The sound of rain heard implies that is raining.\", \"rain_probability\": 0.9 }, ... ] \n",
      "Result: [ { \"tweet\": 1, \"content\": \"The sound of rain tapping on the window\", \"explanation\": \"The sound of rain heard implies that is raining.\", \"rain_probability\": 0.9 }, { \"tweet\": 2, \"content\": \"Boris seems desperate for the rain to finish\", \"explanation\": \"The rain is bad for Boris.\", \"rain_probability\": 0.8 } ]\n",
      "\"\"\"\n",
      "\n",
      "import re\n",
      "import json\n",
      "import sys\n",
      "\n",
      "def get_tweets():\n",
      "    tweets = []\n",
      "    with open('tweets.txt') as f:\n",
      "        for line in f:\n",
      "            tweets.append(line.strip())\n",
      "    return tweets\n",
      "\n",
      "def get_content(tweet):\n",
      "    tweet = tweet.lower()\n",
      "    tweet = re.sub('[^a-z0-9]', ' ', tweet)\n",
      "    tweet = re.sub(' +', ' ', tweet)\n",
      "    return tweet\n",
      "\n",
      "def get_explanation(tweet):\n",
      "    tweet = tweet.lower()\n",
      "    tweet = re.\n"
     ]
    }
   ],
   "source": [
    "text = r'Assign a probability that it is raining to the following tweets. The content of the tweets should hint something about the weather being rainy and not good in general. Tweet 1: \"Well that last rumble of thunder made the house shake, I wasn\\'t scared for a couple of seconds\" Tweet 2: \"#viewfromthe office what a great morning @Grantham and District\". Return the results in a json file like: [ { \"tweet\": 1, \"content\": \"Well that last rumble of thunder made the house shake, I wasn\\'t scared for a couple of seconds\", \"explanation\": \"short explanation of the rain probability based on content of this tweet\", \"rain_probability\": x.x }, ... ] Result: [ { \"tweet\": 1, \"content\":'\n",
    "text = r'''Assign a probability that it is raining to the following tweets. The content of the tweets should hint something about the weather being rainy and not good in general. \n",
    "Tweet 1: \"The sound of rain tapping on the window\" \n",
    "Tweet 2: \"Boris seems desperate for the rain to finish\". \n",
    "Return the results in a json file like: [ { \"tweet\": 1, \"content\": \"The sound of rain tapping on the window\", \"explanation\": \"The sound of rain heard implies that is raining.\", \"rain_probability\": 0.9 }, ... ] \n",
    "Result: [ { \"tweet\": 1, \"content\":'''\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "\n",
    "sample_outputs = model.generate(\n",
    "    input_ids,\n",
    "    temperature=0.2,\n",
    "    do_sample=True, \n",
    "    max_length=400, \n",
    "    top_k=50, \n",
    "    top_p=0.95, \n",
    "    num_return_sequences=3,\n",
    "    early_stopping=True,\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.prepare_inputs_for_generation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap2python3p10llama",
   "language": "python",
   "name": "ap2python3p10llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
