{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize data for Tweets paper\n",
    "Plots included:\n",
    "* Histogram of keyword occurence with rendered emojis\n",
    "* Optional, word cloud (rendering emojis causes issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows update of external libraries without need to reload package\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import zipfile\n",
    "import pathlib\n",
    "import logging\n",
    "import json\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.offsetbox\n",
    "\n",
    "\n",
    "import wget\n",
    "\n",
    "import requests\n",
    "import base64\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import wordcloud\n",
    "import tweepy\n",
    "import a2.twitter.downloader\n",
    "import a2.plotting\n",
    "import a2.dataset\n",
    "import a2.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_DATA = a2.utils.file_handling.get_folder_data()\n",
    "FOLDER_TWEETS = FOLDER_DATA / \"tweets/\"\n",
    "FILE_TWEETS = (\n",
    "    FOLDER_TWEETS\n",
    "    / \"2017_2020_tweets_rain_sun_vocab_emojis_locations_bba_Tp_era5_no_bots_normalized_filtered_weather_stations_fix_predicted_simpledeberta_radar.nc\"\n",
    ")\n",
    "FOLDER_FIGURES = pathlib.Path(\"../../figures/data/tweets/\")\n",
    "FILE_FONT = \"../fonts/noto/NotoEmoji-VariableFont_wght.ttf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tweets = a2.dataset.load_dataset.load_tweets_dataset(FILE_TWEETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"🏔️ OR 🏔️ OR ☀️ OR ☀️ OR 🌞 OR ⛅ OR ⛈️ OR ⛈️ OR 🌤️ OR 🌤️ OR 🌥️ OR 🌥️ OR 🌦️ OR 🌦️ OR 🌧️ OR 🌧️ OR 🌨️ OR 🌨️ OR 🌩️ OR 🌩️ OR ☔ OR ⛄ OR blizzard OR cloudburst OR downpour OR drizzle OR flash flood OR flood OR flood stage OR forecast OR freezing rain OR hail OR ice storm OR lightning OR precipitation OR rain OR rain gauge OR rain shadow OR rainbands OR rain shower OR snow OR snow shower OR snowstorm OR sun OR sunny OR thunder OR thunderstorm\"\n",
    "keywords = header.split(\" OR \")\n",
    "\n",
    "header_no_alts = \"🏔️ OR ☀️ OR 🌞 OR ⛅ OR ⛈️ OR 🌤️ OR 🌥️ OR 🌦️ OR 🌧️ OR 🌨️ OR 🌩️ OR ☔ OR ⛄ OR blizzard OR cloudburst OR downpour OR drizzle OR flash flood OR flood OR flood stage OR forecast OR freezing rain OR hail OR ice storm OR lightning OR precipitation OR rain OR rain gauge OR rain shadow OR rainbands OR rain shower OR snow OR snow shower OR snowstorm OR sun OR sunny OR thunder OR thunderstorm\"\n",
    "keywords_no_alts = header_no_alts.split(\" OR \")\n",
    "keywords_no_alts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_normalized = \" \".join(ds_tweets.text_normalized.values)\n",
    "text_original = \" \".join(ds_tweets.text_original.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $FILE_FONT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordcloud():\n",
    "    normal_word = r\"(?:\\w[\\w']+)\"\n",
    "    # 2+ consecutive punctuations, e.x. :)\n",
    "    ascii_art = r\"(?:[{punctuation}][{punctuation}]+)\".format(punctuation=string.punctuation)\n",
    "    # a single character that is not alpha_numeric or other ascii printable\n",
    "    emoji = r\"(?:[^\\s])(?<![\\w{ascii_printable}])\".format(ascii_printable=string.printable)\n",
    "    regexp = r\"{normal_word}|{ascii_art}|{emoji}\".format(normal_word=normal_word, ascii_art=ascii_art, emoji=emoji)\n",
    "    dir_name = os.path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\n",
    "    # Generate a word cloud image\n",
    "    # The Symbola font includes most emoji\n",
    "    wc = wordcloud.WordCloud(font_path=FILE_FONT, regexp=regexp, width=800, height=400).generate(text_original)\n",
    "\n",
    "    plt.imshow(wc)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_wordcloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "%matplotlib inline\n",
    "\n",
    "occurence = [text_original.count(k) for k in keywords]\n",
    "\n",
    "# matplotlib.use(\"module://mplcairo.tk\")\n",
    "prop = matplotlib.font_manager.FontProperties(fname=FILE_FONT)\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # These two lines need to be set manually\n",
    "plt.rcParams[\"font.family\"] = prop.get_family()\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10), constrained_layout=True)\n",
    "for i, log in enumerate([True, False]):\n",
    "    ax = axs[i]\n",
    "    plot = ax.bar(np.arange(len(occurence)), occurence)\n",
    "    labels = [\"{}\".format(x) for x in keywords]\n",
    "    for rect1, label in zip(plot, labels):\n",
    "        height = rect1.get_height()\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            (rect1.get_x() + rect1.get_width() / 2, height + 5),\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=16,\n",
    "            fontproperties=prop,\n",
    "            rotation=90,\n",
    "        )\n",
    "    ax.tick_params(axis=\"x\", labelrotation=90)\n",
    "    ax.set_xlabel(\"keywords\")\n",
    "    ax.set_ylabel(\"counts\")\n",
    "    if log:\n",
    "        ax.set_yscale(\"log\")\n",
    "plt.draw()\n",
    "plt.show()\n",
    "fig.savefig(FOLDER_FIGURES / \"word_count_all.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading emoji images taken from https://rémy.be/posts/plot-emoji-with-matplotlib/\n",
    "\n",
    "\n",
    "def download_emoji(link, to_folder=\"emoji_images/\"):\n",
    "    output = {}\n",
    "    response = requests.get(emoji_url)\n",
    "    response.raise_for_status()\n",
    "    html_code = BeautifulSoup(response.text, \"html.parser\")\n",
    "    table = html_code.find(\"table\")\n",
    "    emoji = [n.img[\"src\"] for n in table.find_all(attrs={\"class\": \"andr alt\"})]\n",
    "    codes = [c.text for c in table.find_all(attrs={\"class\": \"code\"})]\n",
    "    emojilist = []\n",
    "\n",
    "    for row in table.findAll([\"tr\"])[3:]:\n",
    "        code = row.find_all(\"td\", attrs={\"class\": \"code\"})\n",
    "        image = row.find_all(\"td\", attrs={\"class\": \"andr alt\"})\n",
    "        if code and image:\n",
    "            emojilist.append((code[0].text, image[0].img[\"src\"]))\n",
    "\n",
    "    prefixlen = len(\"data:image/png;base64,\")\n",
    "    for code, data in emojilist:\n",
    "        code = code[2:]\n",
    "        code = code.replace(\" U+\", \"_\")\n",
    "        filename = os.path.join(to_folder, f\"{code}.png\".lower())\n",
    "        os.makedirs(filename, exist_ok=True)\n",
    "        with open(filename, \"wb\") as fh:\n",
    "            fh.write(base64.decodebytes(bytes(data[prefixlen:], \"utf-8\")))\n",
    "        print(\"Wrote to:\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_url = \"http://www.unicode.org/emoji/charts/full-emoji-list.html\"\n",
    "emoji_modifiers_url = \"http://www.unicode.org/emoji/charts/full-emoji-modifiers.html\"\n",
    "\n",
    "download_emoji(emoji_url)\n",
    "# execution only required once, takes a while...\n",
    "# download_emoji(emoji_modifiers_url) # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emojis():\n",
    "    _x = data[\"A\"]\n",
    "    _y = data[\"B\"]\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "    ax.set_xlim(0, 700)\n",
    "    ax.set_ylim(0, 700)\n",
    "\n",
    "    for png, x, y in zip(emoji_png, _x, _y):\n",
    "        emoj = plt.imread(f\"emoji_images/{png}\")\n",
    "        imagebox = matplotlib.offsetbox.OffsetImage(emoj, zoom=0.5)\n",
    "        ab = matplotlib.offsetbox.AnnotationBbox(imagebox, (int(x), int(y)), frameon=False)\n",
    "        ax.add_artist(ab)\n",
    "\n",
    "    plt.title(\"Relative usage\")\n",
    "    plt.xlabel(\"A\")\n",
    "    plt.ylabel(\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurence = [text_original.count(k) for k in keywords_no_alts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurence = np.array(occurence)\n",
    "keywords_no_alts = np.array(keywords_no_alts)\n",
    "min_occurence = 5000\n",
    "mask_occurence = occurence > min_occurence\n",
    "occurence_masked = occurence[mask_occurence]\n",
    "keywords_masked = keywords_no_alts[mask_occurence]\n",
    "prop = matplotlib.font_manager.FontProperties()\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # These two lines need to be set manually\n",
    "plt.rcParams[\"font.family\"] = prop.get_family()\n",
    "fontsize = 13\n",
    "a2.plotting.utils_plotting.set_font(fontsize)\n",
    "logs = [False]\n",
    "fig, axs = plt.subplots(len(logs), 1, figsize=(8, 5), constrained_layout=True, squeeze=False)\n",
    "for i, log in enumerate(logs):\n",
    "    ax = axs[i][0]\n",
    "    plot = a2.plotting.histograms.plot_bar(\n",
    "        bin_centers=range(len(occurence_masked)),\n",
    "        hist=occurence_masked,\n",
    "        width_bars=1,\n",
    "        xlim=None,\n",
    "        ylim=None,\n",
    "        ax=ax,\n",
    "        log=[False, log],\n",
    "        linear_thresh=None,\n",
    "        label_x=None,\n",
    "        label_y=None,\n",
    "        vertical=False,\n",
    "        alpha=1,\n",
    "        font_size=fontsize,\n",
    "        replace_x_labels_at=None,\n",
    "        replace_x_labels_with=None,\n",
    "        replace_y_labels_at=None,\n",
    "        replace_y_labels_with=None,\n",
    "    )\n",
    "    print(keywords_masked)\n",
    "    a2.plotting.histograms.annotate_histogram(ax, plot, keywords_masked, as_label=\"x\", fontsize=fontsize)\n",
    "    ax.set_xlim([-0.5, len(occurence_masked) - 0.5])\n",
    "    a2.plotting.axes_utils.set_axes(ax=ax, label_y=\"Number of keyword occurence\", fontsize=fontsize)\n",
    "fig.savefig(FOLDER_FIGURES / \"occurence_keywords_min5000.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_masked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "06c3f19a037da30281d10f8fbda7f2df02465bd919ed005b52297a6fc2623835"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
